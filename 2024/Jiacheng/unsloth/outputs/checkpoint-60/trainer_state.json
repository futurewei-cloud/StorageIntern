{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.16,
  "eval_steps": 500,
  "global_step": 60,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0026666666666666666,
      "grad_norm": 2.7020883560180664,
      "learning_rate": 4e-05,
      "loss": 4.4659,
      "step": 1
    },
    {
      "epoch": 0.005333333333333333,
      "grad_norm": 2.9549009799957275,
      "learning_rate": 8e-05,
      "loss": 4.5581,
      "step": 2
    },
    {
      "epoch": 0.008,
      "grad_norm": 2.74617338180542,
      "learning_rate": 0.00012,
      "loss": 4.4661,
      "step": 3
    },
    {
      "epoch": 0.010666666666666666,
      "grad_norm": 3.436431646347046,
      "learning_rate": 0.00016,
      "loss": 4.0895,
      "step": 4
    },
    {
      "epoch": 0.013333333333333334,
      "grad_norm": 3.9799656867980957,
      "learning_rate": 0.0002,
      "loss": 3.6253,
      "step": 5
    },
    {
      "epoch": 0.016,
      "grad_norm": 4.429939270019531,
      "learning_rate": 0.00019636363636363636,
      "loss": 3.1119,
      "step": 6
    },
    {
      "epoch": 0.018666666666666668,
      "grad_norm": 3.8633651733398438,
      "learning_rate": 0.00019272727272727274,
      "loss": 2.3594,
      "step": 7
    },
    {
      "epoch": 0.021333333333333333,
      "grad_norm": 3.5443356037139893,
      "learning_rate": 0.0001890909090909091,
      "loss": 1.7428,
      "step": 8
    },
    {
      "epoch": 0.024,
      "grad_norm": 2.5287275314331055,
      "learning_rate": 0.00018545454545454545,
      "loss": 1.5208,
      "step": 9
    },
    {
      "epoch": 0.02666666666666667,
      "grad_norm": 1.817592978477478,
      "learning_rate": 0.00018181818181818183,
      "loss": 1.2714,
      "step": 10
    },
    {
      "epoch": 0.029333333333333333,
      "grad_norm": 1.3739351034164429,
      "learning_rate": 0.0001781818181818182,
      "loss": 1.1546,
      "step": 11
    },
    {
      "epoch": 0.032,
      "grad_norm": 2.1535072326660156,
      "learning_rate": 0.00017454545454545454,
      "loss": 1.3385,
      "step": 12
    },
    {
      "epoch": 0.034666666666666665,
      "grad_norm": 1.6675353050231934,
      "learning_rate": 0.0001709090909090909,
      "loss": 1.0577,
      "step": 13
    },
    {
      "epoch": 0.037333333333333336,
      "grad_norm": 1.245710015296936,
      "learning_rate": 0.00016727272727272728,
      "loss": 0.925,
      "step": 14
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.2560358047485352,
      "learning_rate": 0.00016363636363636366,
      "loss": 1.0061,
      "step": 15
    },
    {
      "epoch": 0.042666666666666665,
      "grad_norm": 0.8841004967689514,
      "learning_rate": 0.00016,
      "loss": 0.8056,
      "step": 16
    },
    {
      "epoch": 0.04533333333333334,
      "grad_norm": 0.9975757598876953,
      "learning_rate": 0.00015636363636363637,
      "loss": 0.8308,
      "step": 17
    },
    {
      "epoch": 0.048,
      "grad_norm": 1.2382382154464722,
      "learning_rate": 0.00015272727272727275,
      "loss": 1.0332,
      "step": 18
    },
    {
      "epoch": 0.050666666666666665,
      "grad_norm": 1.3221899271011353,
      "learning_rate": 0.0001490909090909091,
      "loss": 1.0302,
      "step": 19
    },
    {
      "epoch": 0.05333333333333334,
      "grad_norm": 1.0709819793701172,
      "learning_rate": 0.00014545454545454546,
      "loss": 0.8641,
      "step": 20
    },
    {
      "epoch": 0.056,
      "grad_norm": 0.9699110984802246,
      "learning_rate": 0.00014181818181818184,
      "loss": 0.8443,
      "step": 21
    },
    {
      "epoch": 0.058666666666666666,
      "grad_norm": 1.1401352882385254,
      "learning_rate": 0.0001381818181818182,
      "loss": 0.8359,
      "step": 22
    },
    {
      "epoch": 0.06133333333333333,
      "grad_norm": 0.9233298301696777,
      "learning_rate": 0.00013454545454545455,
      "loss": 0.7356,
      "step": 23
    },
    {
      "epoch": 0.064,
      "grad_norm": 1.6160839796066284,
      "learning_rate": 0.00013090909090909093,
      "loss": 0.8628,
      "step": 24
    },
    {
      "epoch": 0.06666666666666667,
      "grad_norm": 1.3775649070739746,
      "learning_rate": 0.00012727272727272728,
      "loss": 0.9623,
      "step": 25
    },
    {
      "epoch": 0.06933333333333333,
      "grad_norm": 1.0828109979629517,
      "learning_rate": 0.00012363636363636364,
      "loss": 0.8102,
      "step": 26
    },
    {
      "epoch": 0.072,
      "grad_norm": 0.9748664498329163,
      "learning_rate": 0.00012,
      "loss": 0.7425,
      "step": 27
    },
    {
      "epoch": 0.07466666666666667,
      "grad_norm": 1.0749351978302002,
      "learning_rate": 0.00011636363636363636,
      "loss": 0.7541,
      "step": 28
    },
    {
      "epoch": 0.07733333333333334,
      "grad_norm": 1.0890188217163086,
      "learning_rate": 0.00011272727272727272,
      "loss": 0.8225,
      "step": 29
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1438578367233276,
      "learning_rate": 0.00010909090909090909,
      "loss": 0.8158,
      "step": 30
    },
    {
      "epoch": 0.08266666666666667,
      "grad_norm": 1.0413621664047241,
      "learning_rate": 0.00010545454545454545,
      "loss": 0.6933,
      "step": 31
    },
    {
      "epoch": 0.08533333333333333,
      "grad_norm": 0.927615225315094,
      "learning_rate": 0.00010181818181818181,
      "loss": 0.7549,
      "step": 32
    },
    {
      "epoch": 0.088,
      "grad_norm": 0.8674835562705994,
      "learning_rate": 9.818181818181818e-05,
      "loss": 0.6631,
      "step": 33
    },
    {
      "epoch": 0.09066666666666667,
      "grad_norm": 1.3276855945587158,
      "learning_rate": 9.454545454545455e-05,
      "loss": 0.7536,
      "step": 34
    },
    {
      "epoch": 0.09333333333333334,
      "grad_norm": 1.2753005027770996,
      "learning_rate": 9.090909090909092e-05,
      "loss": 0.7232,
      "step": 35
    },
    {
      "epoch": 0.096,
      "grad_norm": 1.1954147815704346,
      "learning_rate": 8.727272727272727e-05,
      "loss": 0.7071,
      "step": 36
    },
    {
      "epoch": 0.09866666666666667,
      "grad_norm": 1.1347525119781494,
      "learning_rate": 8.363636363636364e-05,
      "loss": 0.7273,
      "step": 37
    },
    {
      "epoch": 0.10133333333333333,
      "grad_norm": 1.2598108053207397,
      "learning_rate": 8e-05,
      "loss": 0.7764,
      "step": 38
    },
    {
      "epoch": 0.104,
      "grad_norm": 1.0246587991714478,
      "learning_rate": 7.636363636363637e-05,
      "loss": 0.7289,
      "step": 39
    },
    {
      "epoch": 0.10666666666666667,
      "grad_norm": 1.0610085725784302,
      "learning_rate": 7.272727272727273e-05,
      "loss": 0.7139,
      "step": 40
    },
    {
      "epoch": 0.10933333333333334,
      "grad_norm": 1.6091984510421753,
      "learning_rate": 6.90909090909091e-05,
      "loss": 0.8471,
      "step": 41
    },
    {
      "epoch": 0.112,
      "grad_norm": 1.168563723564148,
      "learning_rate": 6.545454545454546e-05,
      "loss": 0.6738,
      "step": 42
    },
    {
      "epoch": 0.11466666666666667,
      "grad_norm": 1.1407051086425781,
      "learning_rate": 6.181818181818182e-05,
      "loss": 0.6425,
      "step": 43
    },
    {
      "epoch": 0.11733333333333333,
      "grad_norm": 1.0626777410507202,
      "learning_rate": 5.818181818181818e-05,
      "loss": 0.6711,
      "step": 44
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0748587846755981,
      "learning_rate": 5.4545454545454546e-05,
      "loss": 0.6742,
      "step": 45
    },
    {
      "epoch": 0.12266666666666666,
      "grad_norm": 1.096640944480896,
      "learning_rate": 5.090909090909091e-05,
      "loss": 0.6583,
      "step": 46
    },
    {
      "epoch": 0.12533333333333332,
      "grad_norm": 0.8892356157302856,
      "learning_rate": 4.7272727272727275e-05,
      "loss": 0.6985,
      "step": 47
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.8683536648750305,
      "learning_rate": 4.3636363636363636e-05,
      "loss": 0.6341,
      "step": 48
    },
    {
      "epoch": 0.13066666666666665,
      "grad_norm": 1.0602877140045166,
      "learning_rate": 4e-05,
      "loss": 0.636,
      "step": 49
    },
    {
      "epoch": 0.13333333333333333,
      "grad_norm": 0.8758479356765747,
      "learning_rate": 3.6363636363636364e-05,
      "loss": 0.6323,
      "step": 50
    },
    {
      "epoch": 0.136,
      "grad_norm": 0.874713122844696,
      "learning_rate": 3.272727272727273e-05,
      "loss": 0.6367,
      "step": 51
    },
    {
      "epoch": 0.13866666666666666,
      "grad_norm": 1.2021889686584473,
      "learning_rate": 2.909090909090909e-05,
      "loss": 0.7266,
      "step": 52
    },
    {
      "epoch": 0.14133333333333334,
      "grad_norm": 1.1525107622146606,
      "learning_rate": 2.5454545454545454e-05,
      "loss": 0.561,
      "step": 53
    },
    {
      "epoch": 0.144,
      "grad_norm": 1.2131822109222412,
      "learning_rate": 2.1818181818181818e-05,
      "loss": 0.6481,
      "step": 54
    },
    {
      "epoch": 0.14666666666666667,
      "grad_norm": 0.9832658171653748,
      "learning_rate": 1.8181818181818182e-05,
      "loss": 0.6135,
      "step": 55
    },
    {
      "epoch": 0.14933333333333335,
      "grad_norm": 0.8657418489456177,
      "learning_rate": 1.4545454545454545e-05,
      "loss": 0.5427,
      "step": 56
    },
    {
      "epoch": 0.152,
      "grad_norm": 1.0978385210037231,
      "learning_rate": 1.0909090909090909e-05,
      "loss": 0.6922,
      "step": 57
    },
    {
      "epoch": 0.15466666666666667,
      "grad_norm": 1.0202199220657349,
      "learning_rate": 7.272727272727272e-06,
      "loss": 0.6274,
      "step": 58
    },
    {
      "epoch": 0.15733333333333333,
      "grad_norm": 0.9985809326171875,
      "learning_rate": 3.636363636363636e-06,
      "loss": 0.5662,
      "step": 59
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8961251974105835,
      "learning_rate": 0.0,
      "loss": 0.575,
      "step": 60
    }
  ],
  "logging_steps": 1,
  "max_steps": 60,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1815836004126720.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
