{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977003f58df14d0c82eae731caf8e03b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "LlamaModel is using LlamaSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Entities and Relationships:\n",
      " \n",
      "    You are a data scientist working for a company that is building a graph database. Your task is to extract information from data and convert it into a graph database.\n",
      "    Provide a set of Nodes in the form [ENTITY_ID, TYPE, PROPERTIES] and a set of relationships in the form [ENTITY_ID_1, RELATIONSHIP, ENTITY_ID_2, PROPERTIES]. Make the nodes and relationship format a Python-compatible string.\n",
      "    It is important that the ENTITY_ID_1 and ENTITY_ID_2 exist as nodes with a matching ENTITY_ID. If you can't pair a relationship with a pair of nodes, don't add it.\n",
      "    When you find a node or relationship you want to add, try to create a generic TYPE for it that describes the entity. You can also think of it as a label.\n",
      "    The entity may include person, company, event, etc.\n",
      "\n",
      "    Example:\n",
      "    Data: Alice is a lawyer and is 25 years old and Bob is her roommate since 2001. Bob works as a journalist. Alice owns a webpage www.alice.com and Bob owns the webpage www.bob.com.\n",
      "    Nodes: [[\"alice\", \"Person\", {\"age\": 25, \"occupation\": \"lawyer\", \"name\":\"Alice\"}], [\"bob\", \"Person\", {\"occupation\": \"journalist\", \"name\": \"Bob\"}], [\"alice.com\", \"Webpage\", {\"url\": \"www.alice.com\"}], [\"bob.com\", \"Webpage\", {\"url\": \"www.bob.com\"}]]\n",
      "    Relationships: [[\"alice\", \"roommate\", \"bob\", {\"start\": 2021}], [\"alice\", \"owns\", \"alice.com\", {}], [\"bob\", \"owns\", \"bob.com\", {}]]\n",
      "    \n",
      "    Data: The company's history goes back to a small ecommerce shop. There are conflicting reports on SHEIN's origins.\n",
      "    Founded in 2012, the company's history goes back to a small ecommerce shop. It was launched by Chris Xu (CEO), an entrepreneur, and his ex-colleague, Wang Xiaohu, named Nanjing Dianwei Information Technology (NDIT) in 2008.\n",
      "    Lily Peng, a part-time consultant, and known parent who is described as a \"hardworking SEO whiz,\" is also known about the entrepreneur. Some reports describe Xu focused on technical parts while leaving business development, finance, and corporate functions to Xiaohu and Peng.\n",
      "    Xu, who studied at George Washington University, is described by some sources as a Chinese-American.'\n",
      "    Nodes: [[\"chris_xu\", \"Person\", {\"name\": \"Chris Xu\"}], [\"wang_xiaohu\", \"Person\", {\"name\": \"Wang Xiaohu\"}], [\"SHEIN\", \"Company\", {\"name\": \"SHEIN\"}], [\"lily_peng\", \"Person\", {\"name\": \"Lily Peng\"}], [\"tidn\", \"Company\", {\"name\": \"TIDN\"}], [\"nanjing_information_technology\", \"Company\", {\"name\": \"Nanjing Information Technology\"}]]\n",
      "    Relationships: [[\"chris_xu\", \"cofounded_with\", \"wang_xiaohu\", {}], [\"chris_xu\", \"founded\", \"SHEIN\", {}], [\"Chris Xu\", \"focused on\", \"technical parts \", {}], [\"lily_peng\", \"focused on\", \"business and finance part\", {}]]\n",
      "    \n",
      "\n",
      "Data: The quick brown fox jumps over the lazy dog. The dog did not see the fox coming. The fox jumped over the dog.\n",
      "Nodes: [[\"fox\", \"Animal\", {\"name\": \"fox\"}], [\"dog\", \"Animal\", {\"name\": \"dog\"}], [\"quick\", \"Adjective\", {\"name\": \"quick\"}], [\"brown\", \"Adjective\", {\"name\": \"brown\"}], [\"lazy\", \"Adjective\", {\"name\": \"lazy\"}], [\"jumps\", \"Verb\", {\"name\": \"jumps\"}], [\"over\", \"Preposition\", {\"name\": \"over\"}], [\"the\", \"Determiner\", {\"name\": \"the\"}]]\n",
      "Relationships: [[\"fox\", \"jumps_over\", \"dog\", {}], [\"fox\", \"is\", \"quick\", {}], [\"fox\", \"is\", \"brown\", {}], [\"dog\", \"is\", \"lazy\", {}]]\n",
      "\n",
      "    Entity1 Entity2  QV_Value\n",
      "0     quick   quick  0.512222\n",
      "1     quick   brown  0.000000\n",
      "2     quick     fox  0.000000\n",
      "3     quick   jumps  0.000000\n",
      "4     quick    over  0.000000\n",
      "..      ...     ...       ...\n",
      "116     fox    lazy  0.000403\n",
      "117     fox     dog  0.005327\n",
      "118     fox     dog  0.032545\n",
      "119     fox     the  0.067892\n",
      "120     fox     fox  0.563370\n",
      "\n",
      "[121 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "\n",
    "# Add padding token to the tokenizer\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "def generate_system_message() -> str:\n",
    "    return \"\"\"\n",
    "    You are a data scientist working for a company that is building a graph database. Your task is to extract information from data and convert it into a graph database.\n",
    "    Provide a set of Nodes in the form [ENTITY_ID, TYPE, PROPERTIES] and a set of relationships in the form [ENTITY_ID_1, RELATIONSHIP, ENTITY_ID_2, PROPERTIES]. Make the nodes and relationship format a Python-compatible string.\n",
    "    It is important that the ENTITY_ID_1 and ENTITY_ID_2 exist as nodes with a matching ENTITY_ID. If you can't pair a relationship with a pair of nodes, don't add it.\n",
    "    When you find a node or relationship you want to add, try to create a generic TYPE for it that describes the entity. You can also think of it as a label.\n",
    "    The entity may include person, company, event, etc.\n",
    "\n",
    "    Example:\n",
    "    Data: Alice is a lawyer and is 25 years old and Bob is her roommate since 2001. Bob works as a journalist. Alice owns a webpage www.alice.com and Bob owns the webpage www.bob.com.\n",
    "    Nodes: [[\"alice\", \"Person\", {\"age\": 25, \"occupation\": \"lawyer\", \"name\":\"Alice\"}], [\"bob\", \"Person\", {\"occupation\": \"journalist\", \"name\": \"Bob\"}], [\"alice.com\", \"Webpage\", {\"url\": \"www.alice.com\"}], [\"bob.com\", \"Webpage\", {\"url\": \"www.bob.com\"}]]\n",
    "    Relationships: [[\"alice\", \"roommate\", \"bob\", {\"start\": 2021}], [\"alice\", \"owns\", \"alice.com\", {}], [\"bob\", \"owns\", \"bob.com\", {}]]\n",
    "    \n",
    "    Data: The company's history goes back to a small ecommerce shop. There are conflicting reports on SHEIN's origins.\n",
    "    Founded in 2012, the company's history goes back to a small ecommerce shop. It was launched by Chris Xu (CEO), an entrepreneur, and his ex-colleague, Wang Xiaohu, named Nanjing Dianwei Information Technology (NDIT) in 2008.\n",
    "    Lily Peng, a part-time consultant, and known parent who is described as a \"hardworking SEO whiz,\" is also known about the entrepreneur. Some reports describe Xu focused on technical parts while leaving business development, finance, and corporate functions to Xiaohu and Peng.\n",
    "    Xu, who studied at George Washington University, is described by some sources as a Chinese-American.'\n",
    "    Nodes: [[\"chris_xu\", \"Person\", {\"name\": \"Chris Xu\"}], [\"wang_xiaohu\", \"Person\", {\"name\": \"Wang Xiaohu\"}], [\"SHEIN\", \"Company\", {\"name\": \"SHEIN\"}], [\"lily_peng\", \"Person\", {\"name\": \"Lily Peng\"}], [\"tidn\", \"Company\", {\"name\": \"TIDN\"}], [\"nanjing_information_technology\", \"Company\", {\"name\": \"Nanjing Information Technology\"}]]\n",
    "    Relationships: [[\"chris_xu\", \"cofounded_with\", \"wang_xiaohu\", {}], [\"chris_xu\", \"founded\", \"SHEIN\", {}], [\"Chris Xu\", \"focused on\", \"technical parts \", {}], [\"lily_peng\", \"focused on\", \"business and finance part\", {}]]\n",
    "    \"\"\"\n",
    "\n",
    "def extract_entities_and_relationships(paragraph):\n",
    "    system_message = generate_system_message()\n",
    "    prompt = f\"{system_message}\\n\\nData: {paragraph}\"\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "    \n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=1024, num_beams=5, early_stopping=True, pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "# Example paragraph input\n",
    "paragraph = \"The quick brown fox jumps over the lazy dog. The dog did not see the fox coming.\"\n",
    "\n",
    "# Extract entities and relationships\n",
    "entities_relationships = extract_entities_and_relationships(paragraph)\n",
    "print(\"Extracted Entities and Relationships:\\n\", entities_relationships)\n",
    "\n",
    "def get_attention_values(paragraph):\n",
    "    # Tokenize the input paragraph\n",
    "    inputs = tokenizer(paragraph, return_tensors='pt', padding=True, truncation=True)\n",
    "    input_ids = inputs.input_ids\n",
    "    attention_mask = inputs.attention_mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, output_attentions=True)\n",
    "\n",
    "    # Extract attentions\n",
    "    attentions = outputs.attentions  # A tuple containing attention values for all layers\n",
    "    return attentions, inputs\n",
    "\n",
    "# Run the test case to get attention values\n",
    "attentions, inputs = get_attention_values(paragraph)\n",
    "\n",
    "# Specify the layer and head index\n",
    "layer_index = -1  # Last layer\n",
    "head_index = 0    # First attention head\n",
    "\n",
    "# Attention values shape: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "selected_attention = attentions[layer_index][0][head_index].detach().cpu().numpy()\n",
    "\n",
    "# Get token labels and remove special token markers\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "tokens = [token.replace('Ġ', '') for token in tokens]\n",
    "\n",
    "# Predefined extracted entities\n",
    "entities = [\"fox\", \"dog\", \"quick\", \"brown\", \"lazy\", \"jumps\", \"over\", \"the\"]\n",
    "\n",
    "# Create a DataFrame with entities and qv values\n",
    "data = []\n",
    "seq_len = len(tokens)\n",
    "for i in range(seq_len):\n",
    "    for j in range(seq_len):\n",
    "        if tokens[i] in entities and tokens[j] in entities:\n",
    "            entity_1 = tokens[i]\n",
    "            entity_2 = tokens[j]\n",
    "            qv_value = selected_attention[i][j]\n",
    "            data.append([entity_1, entity_2, qv_value])\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Entity1', 'Entity2', 'QV_Value'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predefined extracted entities\n",
    "relationships = [\n",
    "    [\"fox\", \"jumps_over\", \"dog\", {}],\n",
    "    [\"fox\", \"is\", \"quick\", {}],\n",
    "    [\"fox\", \"is\", \"brown\", {}],\n",
    "    [\"dog\", \"is\", \"lazy\", {}]\n",
    "]\n",
    "entity1 = []\n",
    "entity2 = []\n",
    "for rel in relationships:\n",
    "    entity1.append(rel[0])\n",
    "    entity2.append(rel[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Entity1 Entity2  QV_Value\n",
      "0     fox     dog  0.000000\n",
      "1     fox   quick  0.025327\n",
      "2     fox   brown  0.071750\n",
      "3     dog    lazy  0.045116\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Extract QV values for each entity pair in relationships\n",
    "for ent1, ent2 in zip(entity1, entity2):\n",
    "    if ent1 in tokens and ent2 in tokens:\n",
    "        ent1_index = tokens.index(ent1)\n",
    "        ent2_index = tokens.index(ent2)\n",
    "        qv_value = selected_attention[ent1_index][ent2_index]\n",
    "        results.append([ent1, ent2, qv_value])\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results, columns=['Entity1', 'Entity2', 'QV_Value'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the layer and head index\n",
    "layer_index = 16  # middle layer \n",
    "head_index = 0    # First attention head\n",
    "\n",
    "# Attention values shape: (batch_size, num_heads, sequence_length, sequence_length)\n",
    "selected_attention = attentions[layer_index][0][head_index].detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Entity1 Entity2  QV_Value\n",
      "0     fox     dog  0.000000\n",
      "1     fox   quick  0.001653\n",
      "2     fox   brown  0.003033\n",
      "3     dog    lazy  0.000813\n"
     ]
    }
   ],
   "source": [
    "# Create a list to store the results\n",
    "results = []\n",
    "\n",
    "# Extract QV values for each entity pair in relationships\n",
    "for ent1, ent2 in zip(entity1, entity2):\n",
    "    if ent1 in tokens and ent2 in tokens:\n",
    "        ent1_index = tokens.index(ent1)\n",
    "        ent2_index = tokens.index(ent2)\n",
    "        qv_value = selected_attention[ent1_index][ent2_index]\n",
    "        results.append([ent1, ent2, qv_value])\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "df = pd.DataFrame(results, columns=['Entity1', 'Entity2', 'QV_Value'])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tune LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.3.0 available.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b31baf3e811b448c95320588e2ff613b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", eval_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
